{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes:  2\n",
      "Class 0: (205, 64, 64)\n",
      "Class 1: (205, 64, 64)\n",
      "\n",
      "x data shape:  (410, 64, 64)\n",
      "y data shape:  (410, 2)\n",
      "\n",
      "x train data shape:  (348, 1, 64, 64)\n",
      "x validation data shape:  (62, 1, 64, 64)\n",
      "y train data shape:  (62, 2)\n",
      "y validation data shape:  (62, 2)\n"
     ]
    }
   ],
   "source": [
    "#Settings\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "import sys\n",
    "import numpy\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd #data processing\n",
    "import warnings\n",
    "import matplotlib.image as mpimg\n",
    "import torch\n",
    "warnings.filterwarnings('ignore')\n",
    "numpy.set_printoptions(threshold=sys.maxsize) #full print setting\n",
    "#--------------------------------------------------------------------------------------\n",
    "import torch\n",
    "\n",
    "\n",
    "from IPython.core.debugger import set_trace # debug\n",
    "import torch.nn as nn\n",
    "import torch.optim as optimizer\n",
    "#-----------------------------------\n",
    "#Settings\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "import sys\n",
    "import numpy\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd #data processing\n",
    "import warnings\n",
    "import matplotlib.image as mpimg\n",
    "import torch\n",
    "warnings.filterwarnings('ignore')\n",
    "numpy.set_printoptions(threshold=sys.maxsize) #full print setting\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "\n",
    "\n",
    "def makeBatch(input, output, channel, batchSize):\n",
    "    #This function takes  as input 4D array (numberOfSample, channel,input.shape[2](m), input.shape[3](n)) then returns\n",
    "    # 5D array (batchIndex, batchSize, channel, input.shape[2](m), input.shape[3](n))\n",
    "    \n",
    "    numberOfSample = input.shape[0]\n",
    "    channel = input.shape[1]\n",
    "    m = input.shape[2]\n",
    "    n = input.shape[3]\n",
    "    \n",
    "    batchIndex = int(numberOfSample/batchSize)\n",
    "    print(\"Numbe of batch:\",batchIndex)\n",
    "    \n",
    "    x = np.ones((batchIndex,batchSize, channel,m,n))\n",
    "    y = np.ones((batchIndex,batchSize,output.shape[1]))\n",
    "        \n",
    "    #result = np.zeros(batchIndex, batchSize, channel, m, n)\n",
    "    \n",
    "    for i in range(batchIndex):\n",
    "        \n",
    "        x[i] = input[i*batchSize:(i+1)*batchSize][:][:][:]\n",
    "        y[i] = output[i*batchSize:(i+1)*batchSize][:]\n",
    "\n",
    "    return x,y\n",
    "\n",
    "\n",
    "\n",
    "def generateLabeledData(input,batch):\n",
    "    \n",
    "    print(\"Number of classes: \", len(input))\n",
    "    \n",
    "    numberOfSamples = 0\n",
    "    \n",
    "    x = []\n",
    "    y = []\n",
    "    \n",
    "    for i in range(len(input)):\n",
    "        \n",
    "        if (i == 0):\n",
    "            print(\"Class {}: {}\".format(i,input[str(i)].shape))\n",
    "            x = input[str(i)]\n",
    "            \n",
    "            rowLabel = np.zeros((1,len(input)))\n",
    "            rowLabel[0][i]=1\n",
    "            label = rowLabel\n",
    "            \n",
    "            for k in range(input[str(i)].shape[0]-1):\n",
    "                 label = np.concatenate((label,rowLabel),axis=0)\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            print(\"Class {}: {}\".format(i,input[str(i)].shape))\n",
    "            x = np.concatenate((x,input[str(i)] ),axis=0)\n",
    "            \n",
    "            rowLabel = np.zeros((1,len(input)))\n",
    "            rowLabel[0][i]=1\n",
    "            \n",
    "            for k in range(input[str(i)].shape[0]):\n",
    "                 label = np.concatenate((label,rowLabel),axis=0)\n",
    "            y = label\n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "    print(\"\\nx data shape: \",x.shape)\n",
    "    print(\"y data shape: \",y.shape)\n",
    "    \n",
    "    if batch == False:\n",
    "        split_ratio = 0.15\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size= split_ratio, random_state=42)\n",
    "        #Adding channel 3D array to 4D array (numberOfSamples, Channel, m, n)\n",
    "        x_train = np.expand_dims(x_train, axis=1)\n",
    "        x_train = np.tile(x_train, (1,1,1,1))\n",
    "        x_test = np.expand_dims(x_test, axis=1)\n",
    "        x_test = np.tile(x_test, (1,1,1,1))\n",
    "        print(\"\\nx train data shape: \",x_train.shape)\n",
    "        print(\"x validation data shape: \",x_test.shape)\n",
    "        print(\"y train data shape: \",y_test.shape)\n",
    "        print(\"y validation data shape: \",y_test.shape)\n",
    "        \n",
    "    if(batch==True):\n",
    "        split_ratio = 0.5\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size= split_ratio, random_state=42)\n",
    "        #Adding channel 3D array to 4D array (numberOfSamples, Channel, m, n)\n",
    "        x_train = np.expand_dims(x_train, axis=1)\n",
    "        x_train = np.tile(x_train, (1,1,1,1))\n",
    "        x_test = np.expand_dims(x_test, axis=1)\n",
    "        x_test = np.tile(x_test, (1,1,1,1))\n",
    "        \n",
    "        # Making Batch\n",
    "        channel = 1\n",
    "        batchSize = 20\n",
    "        x_train, y_train = makeBatch(x_train, y_train, channel, batchSize)\n",
    "        x_test, y_test = makeBatch(x_test, y_test, channel, batchSize)\n",
    "        print(\"\\nx train data after batching: {}\".format(x_train.shape))\n",
    "        print(\"y train data after batching: {}\".format(y_train.shape))\n",
    "        print(\"x validation data after batching: {}\".format(x_test.shape))\n",
    "        print(\"y validation data after batching: {} \\n\".format(y_test.shape))\n",
    "\n",
    "\n",
    "   \n",
    "    \n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "#MAIN\n",
    "#******************************************************************\n",
    "    \n",
    "\n",
    "#load data set\n",
    "images = np.load(\"X.npy\")\n",
    "y = np.load(\"Y.npy\")\n",
    "\n",
    "x = {}\n",
    "\n",
    "x[\"0\"] = np.array(images[204:409])\n",
    "x[\"1\"] = np.array(images[822:1027])\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "epoch = 1000\n",
    "learningRate = 0.001\n",
    "loadingRate = 10\n",
    "batch  = False\n",
    "\n",
    "x_train, x_test, y_train, y_test = generateLabeledData(x,batch)\n",
    "\n",
    "x_train = torch.from_numpy(x_train).float()\n",
    "x_validation = torch.from_numpy(x_test).float()\n",
    "y_train = torch.from_numpy(y_train).float()\n",
    "y_validation = torch.from_numpy(y_test).float()\n",
    "\n",
    "#train(x_train, x_test, y_train, y_test, model, epoch, learningRate, loadingRate, batch)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] : Training Loss: 0.2561519742012024\n",
      "       Validation Loss: 0.25600308179855347\n",
      "\n",
      "\n",
      "Test Accuracy: 46.77418899536133 %\n",
      "\n",
      "\n",
      "[Epoch 2] : Training Loss: 0.25292128324508667\n",
      "       Validation Loss: 0.24951006472110748\n",
      "\n",
      "\n",
      "Test Accuracy: 45.16128921508789 %\n",
      "\n",
      "\n",
      "[Epoch 3] : Training Loss: 0.2504844665527344\n",
      "       Validation Loss: 0.24803556501865387\n",
      "\n",
      "\n",
      "Test Accuracy: 80.6451644897461 %\n",
      "\n",
      "\n",
      "[Epoch 4] : Training Loss: 0.2503388822078705\n",
      "       Validation Loss: 0.24691353738307953\n",
      "\n",
      "\n",
      "Test Accuracy: 59.67741775512695 %\n",
      "\n",
      "\n",
      "[Epoch 5] : Training Loss: 0.24526411294937134\n",
      "       Validation Loss: 0.24236564338207245\n",
      "\n",
      "\n",
      "Test Accuracy: 85.48387145996094 %\n",
      "\n",
      "\n",
      "[Epoch 6] : Training Loss: 0.25121477246284485\n",
      "       Validation Loss: 0.23858298361301422\n",
      "\n",
      "\n",
      "Test Accuracy: 83.8709716796875 %\n",
      "\n",
      "\n",
      "[Epoch 7] : Training Loss: 0.2479199916124344\n",
      "       Validation Loss: 0.2404772937297821\n",
      "\n",
      "\n",
      "Test Accuracy: 46.77418899536133 %\n",
      "\n",
      "\n",
      "[Epoch 8] : Training Loss: 0.24229775369167328\n",
      "       Validation Loss: 0.24021148681640625\n",
      "\n",
      "\n",
      "Test Accuracy: 46.77418899536133 %\n",
      "\n",
      "\n",
      "[Epoch 9] : Training Loss: 0.24035567045211792\n",
      "       Validation Loss: 0.23317252099514008\n",
      "\n",
      "\n",
      "Test Accuracy: 70.96774291992188 %\n",
      "\n",
      "\n",
      "[Epoch 10] : Training Loss: 0.2337694764137268\n",
      "       Validation Loss: 0.22193634510040283\n",
      "\n",
      "\n",
      "Test Accuracy: 93.54838562011719 %\n",
      "\n",
      "\n",
      "[Epoch 11] : Training Loss: 0.2250925898551941\n",
      "       Validation Loss: 0.2156553566455841\n",
      "\n",
      "\n",
      "Test Accuracy: 72.58064270019531 %\n",
      "\n",
      "\n",
      "[Epoch 12] : Training Loss: 0.23003104329109192\n",
      "       Validation Loss: 0.21156617999076843\n",
      "\n",
      "\n",
      "Test Accuracy: 85.48387145996094 %\n",
      "\n",
      "\n",
      "[Epoch 13] : Training Loss: 0.2208423912525177\n",
      "       Validation Loss: 0.21064843237400055\n",
      "\n",
      "\n",
      "Test Accuracy: 93.54838562011719 %\n",
      "\n",
      "\n",
      "[Epoch 14] : Training Loss: 0.21861717104911804\n",
      "       Validation Loss: 0.20314238965511322\n",
      "\n",
      "\n",
      "Test Accuracy: 93.54838562011719 %\n",
      "\n",
      "\n",
      "[Epoch 15] : Training Loss: 0.20859064161777496\n",
      "       Validation Loss: 0.1955103725194931\n",
      "\n",
      "\n",
      "Test Accuracy: 93.54838562011719 %\n",
      "\n",
      "\n",
      "[Epoch 16] : Training Loss: 0.2021443098783493\n",
      "       Validation Loss: 0.18865641951560974\n",
      "\n",
      "\n",
      "Test Accuracy: 88.70967864990234 %\n",
      "\n",
      "\n",
      "[Epoch 17] : Training Loss: 0.19694921374320984\n",
      "       Validation Loss: 0.18456535041332245\n",
      "\n",
      "\n",
      "Test Accuracy: 93.54838562011719 %\n",
      "\n",
      "\n",
      "[Epoch 18] : Training Loss: 0.19346584379673004\n",
      "       Validation Loss: 0.17828086018562317\n",
      "\n",
      "\n",
      "Test Accuracy: 93.54838562011719 %\n",
      "\n",
      "\n",
      "[Epoch 19] : Training Loss: 0.18789726495742798\n",
      "       Validation Loss: 0.16950993239879608\n",
      "\n",
      "\n",
      "Test Accuracy: 90.32257843017578 %\n",
      "\n",
      "\n",
      "[Epoch 20] : Training Loss: 0.18266144394874573\n",
      "       Validation Loss: 0.16319416463375092\n",
      "\n",
      "\n",
      "Test Accuracy: 90.32257843017578 %\n",
      "\n",
      "\n",
      "[Epoch 21] : Training Loss: 0.1731473207473755\n",
      "       Validation Loss: 0.1585676074028015\n",
      "\n",
      "\n",
      "Test Accuracy: 95.16129302978516 %\n",
      "\n",
      "\n",
      "[Epoch 22] : Training Loss: 0.1732984483242035\n",
      "       Validation Loss: 0.15382418036460876\n",
      "\n",
      "\n",
      "Test Accuracy: 95.16129302978516 %\n",
      "\n",
      "\n",
      "[Epoch 23] : Training Loss: 0.17230060696601868\n",
      "       Validation Loss: 0.14894999563694\n",
      "\n",
      "\n",
      "Test Accuracy: 95.16129302978516 %\n",
      "\n",
      "\n",
      "[Epoch 24] : Training Loss: 0.1632383018732071\n",
      "       Validation Loss: 0.14280539751052856\n",
      "\n",
      "\n",
      "Test Accuracy: 95.16129302978516 %\n",
      "\n",
      "\n",
      "[Epoch 25] : Training Loss: 0.16008241474628448\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-978653507321>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    167\u001b[0m             \u001b[1;31m#print(loss.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"[Epoch {}] : Training Loss: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\PROGRAM FILES\\Anaconda\\envs\\staj_projesi\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \"\"\"\n\u001b[1;32m--> 102\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\PROGRAM FILES\\Anaconda\\envs\\staj_projesi\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from IPython.core.debugger import set_trace # debug\n",
    "import torch.nn as nn\n",
    "import torch.optim as optimizer\n",
    "#-----------------------------------\n",
    "#Settings\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "import sys\n",
    "import numpy\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd #data processing\n",
    "import warnings\n",
    "import matplotlib.image as mpimg\n",
    "import torch\n",
    "warnings.filterwarnings('ignore')\n",
    "numpy.set_printoptions(threshold=sys.maxsize) #full print setting\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "def load_checkpoint(filepath):\n",
    "    checkpoint = torch.load(filepath)\n",
    "    model = checkpoint['model']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    for parameter in model.parameters():\n",
    "        parameter.requires_grad = False\n",
    "\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def prediction(x_validation):\n",
    "    prediction = model(x_validation)\n",
    "\n",
    "    thresholdPrediction = torch.zeros((prediction.shape[0],2))\n",
    "   \n",
    "    # if z is bigger than 0.5, our prediction is sign one (y_head=1),\n",
    "    # if z is smaller than 0.5, our prediction is sign zero (y_head=0),\n",
    "    for i in range(prediction.shape[0]):\n",
    "        if prediction[i][0].item()>prediction[i][1].item():\n",
    "            thresholdPrediction[i][0] = 1\n",
    "            thresholdPrediction[i][1] = 0\n",
    "        else:\n",
    "            thresholdPrediction[i][0] = 0\n",
    "            thresholdPrediction[i][1] = 1\n",
    "               \n",
    "    return thresholdPrediction\n",
    "\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        channel = 15\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels = 1, out_channels = channel, kernel_size = 7) \n",
    "        #torch.nn.init.xavier_uniform(self.conv1.weight)\n",
    "        self.conv2 = torch.nn.Conv2d(in_channels = channel, out_channels = channel, kernel_size = 9)\n",
    "        \n",
    "        self.conv3 = torch.nn.Conv2d(in_channels = channel, out_channels =channel, kernel_size = 5)\n",
    "        \n",
    "        \n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        \n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "    \n",
    "        self.beta1 = nn.Linear(channel*29*29, 3)\n",
    "        #torch.nn.init.xavier_uniform(self.beta1.weight)\n",
    "        self.beta2 = nn.Linear(3, 10)\n",
    "        #torch.nn.init.xavier_uniform(self.beta2.weight)\n",
    "        self.beta3 = nn.Linear(10, 30)\n",
    "        self.beta4 = nn.Linear(30, 2)\n",
    "        #torch.nn.init.xavier_uniform(self.beta3.weight)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \n",
    "        channel=15\n",
    "       \n",
    "        y=self.conv1(X) \n",
    "        y=torch.nn.functional.relu(y)\n",
    "        y=self.pool(y) \n",
    "        \n",
    "        y=self.dropout1(y)\n",
    "        \n",
    "        #print(y.shape)\n",
    "        \n",
    "        y = y.view(X.shape[0], channel*29*29)\n",
    "        \n",
    "        #print(y.shape)\n",
    "     \n",
    "        y=self.beta1(y)\n",
    "        y=torch.nn.functional.relu(y)\n",
    "        y=self.beta2(y)\n",
    "        y=torch.nn.functional.relu(y)\n",
    "        \n",
    "        y=self.dropout1(y)\n",
    "        \n",
    "        y=self.beta3(y)\n",
    "        y=self.beta4(y)\n",
    "    \n",
    "        y = torch.nn.functional.softmax(y, dim=None)\n",
    "        \n",
    "        \n",
    "        \n",
    "        return y\n",
    "#***************************************************************************************************************************\n",
    "\n",
    "loadParameters = False # True ise eğitime geçmişte eğitilen parameterlerle başlar.\n",
    "learning_rate = 0.001\n",
    "epoch = 1000\n",
    "loadingRate = 10 # Loading and making prediction at epoch every loadParameters times \n",
    "\n",
    "if(loadParameters == True):\n",
    "    model = model = load_checkpoint('93 Epoch 370 Checkpoint.pth') #Geçmişte eğitilen bir model üzerinden forward propagation yapılır.\n",
    "else:\n",
    "    model = model = Net()\n",
    "    \n",
    "\"\"\"loss_fn = nn.MultiLabelSoftMarginLoss(weight=None, reduce=False)\n",
    "loss_fn = nn.BCEWithLogitsLoss()\"\"\"\n",
    "loss_fn = nn.MSELoss()\n",
    "#optimizer = optimizer.SGD(model.parameters(), lr= learning_rate) #optimizer is defined\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "#***************************************************************************************************************************\n",
    "\n",
    "epoch_list = []\n",
    "validation_loss_list = []\n",
    "training_loss_list = []\n",
    "accuracy_list = []\n",
    "\n",
    "for i in range(epoch):\n",
    "\n",
    "        if(batch==True):\n",
    "\n",
    "            for k in range(x_train.shape[0]):\n",
    "\n",
    "                epoch_list.append(i)\n",
    "\n",
    "                model.train()\n",
    "\n",
    "                optimizer.zero_grad() #optimizer gradientleri sıfırlandı.\n",
    "\n",
    "                y_prediction = model(x_train[k][:][:][:][:]) #tahmin yapıldı\n",
    "                loss = loss_fn(y_prediction, y_train[k][:][:]) #loss hesaplandı\n",
    "                loss.backward() #türevler hesaplandı\n",
    "                optimizer.step() #optimizer gradientleri güncelledi\n",
    "                training_loss_list.append(loss.item())\n",
    "                print(\"Epoch {} : Batch {} : Train Loss {}\".format(i+1,k+1,loss))\n",
    "\n",
    "                # Eval\n",
    "                model.eval()  # <-- here\n",
    "                with torch.no_grad():\n",
    "                    y_validation_prediction = model(x_validation[k][:][:][:][:])  \n",
    "                loss = loss_fn(y_validation_prediction, y_validation[k][:][:])\n",
    "                validation_loss_list.append(loss.item())\n",
    "                print(\" Validation Loss {}\\n\".format(loss.item()))\n",
    "\n",
    "        if(batch==False):\n",
    "\n",
    "            model.train()\n",
    "            optimizer.zero_grad() \n",
    "            y_prediction = model(x_train) \n",
    "            \n",
    "            #print(y_prediction)\n",
    "            \n",
    "            loss = loss_fn(y_prediction, y_train) \n",
    "            #print(loss.shape)\n",
    "            print(\"[Epoch {}] : Training Loss: {}\".format(i+1,loss))\n",
    "            loss.backward() \n",
    "            optimizer.step() \n",
    "            \n",
    "            \n",
    "            model.eval() \n",
    "            with torch.no_grad():\n",
    "                y_validation_prediction = model(x_validation)  \n",
    "            loss = loss_fn(y_validation_prediction, y_validation)\n",
    "            print(\"       Validation Loss: {}\\n\".format(loss))\n",
    "            \n",
    "            \n",
    "            #Prediction\n",
    "            thresholdPrediction = prediction(x_validation)\n",
    "            #print(\"Y validation\\n\",y_validation)\n",
    "            print(\"\\nTest Accuracy: {} %\".format(100 - torch.mean(torch.abs(thresholdPrediction - y_validation)) * 100))\n",
    "            print(\"\\n\")\n",
    "            \n",
    "     \n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0.])\n",
      "tensor([1., 0.])\n"
     ]
    }
   ],
   "source": [
    "sampleID = 19\n",
    "\n",
    "print(y_validation[sampleID])\n",
    "print(thresholdPrediction[sampleID])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
